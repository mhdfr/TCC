


Uma pessoa faz os exames do coração anualmente. Leva-os até o o seu médico de confiança, o mesmo verifica se o paciente possui ou não uma doença  do coração ou indicios de uma.  Em alguns casos é de simples percepção a existência de alguma anormalidade. Mas é para os que não são? Como podemos aumentar a acuidade e evitar mortes?

Pois, segundo world-heart-federation.org, 33% de todas as pessoam que morrem, foram acometidas por doenças do coração.

Uma possível  solução é usar a modelagem preditiva para averiguar  a possibilidade do paciente possuir uma doença cardíaca. 


A modelagem preditiva de classificação é a tarefa de aproximar uma função de mapeamento (f) de variáveis ​​de entrada (X) para variáveis ​​de saída discretas (y).

As variáveis ​​de saída são frequentemente chamadas de rótulos ou categorias. A função de mapeamento prevê a classe ou categoria para uma determinada observação.

Por exemplo, um email de texto pode ser classificado como pertencente a uma das duas classes: "spam" e "não spam".

    Um problema de classificação requer que os exemplos sejam classificados em uma de duas ou mais classes.
    Uma classificação pode ter variáveis ​​de entrada com valor real ou discretas.
    Um problema com duas classes é chamado de problema de classificação binária ou de duas classes.
    Um problema em que um exemplo é atribuído a várias classes é chamado de problema de classificação com vários rótulos.

É comum que os modelos de classificação prevejam um valor contínuo como a probabilidade de um determinado exemplo pertencer a cada classe de saída. As probabilidades podem ser interpretadas como a probabilidade ou a confiança de um determinado exemplo pertencente a cada classe. Uma probabilidade prevista pode ser convertida em um valor de classe, selecionando o rótulo da classe que tem a maior probabilidade.

Por exemplo, um email de texto específico pode ter as probabilidades de 0,1 como sendo "spam" e 0,9 como "sem spam". Podemos converter essas probabilidades em um rótulo de classe selecionando o rótulo "não é spam", pois tem a maior probabilidade prevista.



O método que utilizamos de classificação  irá fornecer 0 como resultado se  paciente não possui doença e 1 se possui.


Os dados analisados possuem as seguintes informações dos pacientes.

-- 1. Idade
-- 2. Sexo
-- 3. Tipo de Dor no Peito(4 valores diferentes)
-- 4. Pressão sanguínea em repouso
-- 5. Colesterol(ruim)  em mg/dl 
-- 6. Açucar no sangue > 120 mg/dl 
-- 7. Resultado do eletrocardiograma em repouso (valores 0,1,2) 
-- 8. frequencia cardíaca miníma alcançada
-- 9. Dor no peito induzida por exercício físico
-- 10. oldpeak = ST depression induced by exercise relative to rest 
-- 11. the slope of the peak exercise ST segment 
-- 12. number of major vessels (0-3) colored by flourosopy 
-- 13. talassemia  0 = normal; 1 = fixed defect; 2 = reversable defec

São de domínio público e  fornecidos pela Cleveland Hearth Association  disponíveis em um repositório público http://archive.ics.uci.edu/ml/datasets/statlog+(heart), os analisados, em particular, são um subconjunto, presente na competição de machine learning do website drivendata.org.

Vamos detalhar os passos de nossa análise.

Primeiramente vamos dividir nossos dados em duas partes, uma para o treino de nosso algoritmo e outra para o teste. Dessa forma, conseguimos analisar a performace do algoritmo em dados que não foram 'vistos', ou seja, dados não presentes no treino, assim, vemos como ele supostamente se comportará em novos dados.Aqui, utilizamos a biblioteca ScitikLearn, o módulo TrainTestSPlit em específico. Utilizamos a razão de 70/30, ou seja, 70% dos dados para treino e 30% de dados para teste.

-----Código em python

Observe que alguns atributos que assumem numeros reais estão em escalas diferentes, para que a diferença de escala não seja um influenciador no modelo, vamos transformá-las, de modo que, estejam entre 0 e 1. Aqui, utilizamos a biblioteca ScitikLearn, o módulo MinMaxScaler em específico. 

--código em Python

Também há variáveis que possuem dados categóricos, vamos alterá-los para que também se tornem números, sendo a escala dos mesmo de acordo com a quantidade de categorias. Por exempo, ao transformamos sexo, denominaremos mulheres com o número 0 e homens com o número 1. Iremos utilizar a biblioteca Python OneHotEncoding[] que nos permite, de maneira simples realizar essa mudança.

----código em python


O algoritmo que iremos utilizar é denominado XGboost. É um algoritmo de aprendizado de máquina  supervisionado, da familia dos que utilizam o método de gradiente boosting em uma arvóre de decisão.[    ].

Foi criado por [     ] em  em 2014 e desde da época, tem sido o principal algoritmo utilizado em competições de aprendizado de máquina[       kaggle ].
Para a reproducibilidade do resultado, como um dos parâmetros do algoritmo, iremos utilizar 'random_seed=42'**, tal valor não afeta a performace do mesmo, é apenas um número escolhido ao acaso, para que o valor inicial seja o mesmo toda vez que Xgboost for aplicado.
 Outros parâmetros são: Penalty e Max-Depth.O primeiro é  utilizado para que o algoritmo não se sobreajuste sobre os dados de treino, ele penaliza os coeficientes de variáveis com maior valor, os reduzindo, dessa forma, o coeficiente de algumas da variáveis vai a zero.Tornando assim, o problema menos complexo.Tal penalidade é chamada de Regressao de Lasso[].
 O segundo, determina o tamanho das arvóres que consideraremos. Quanto maior, maiores são nossas árvores.**(Como um padrão dos algoritmos que utilizam random_seed, o número 42 é escolhido devido filme "Guia dos Mochileiros das Galáxias, no qual o número 42 é  dito como a resposta para todas as perguntas do universo.")


---código em python



O proximo passo é a validação cruzada. Ela permite verificar como o algoritmo se comporta, com as variáveis selecionadas pela penalidade adicionada anteriormente. Funciona do seguinte modo, dividimos nossa base de treino em 5 partes. Treinamos o algoritmo em 4 delas e testamos previamente a pontuação na 5, fazemos isso para todas as partições, ou seja, todas são utilizadas como treino e teste. Desse modo, conseguimos observar o comportamento do algoritmo com diferentes dados.(O método de validação cruzada também pode ser utilizado para otimizar os parâmetros do algoritmo, aqui, não utilizamos tal abordagem.)[    ]
Tal forma é feita da seguinte forma

--código python



Por fim, verificamos o acerto de nosso algoritmo, para tal, será utilizada uma matriz de confusão[    ].
É um tabela que mostra as frequências de classificação para cada classe do modelo. Ela vai nos mostrar as frequências:
Verdadeiro positivo: A classe que estamos buscando foi prevista corretamente.
Falso positivo: A classe que estamos buscando prever foi prevista incorretamente
Falso verdadeiro: A classe que não estamos buscando prever foi prevista corretamente.
Falso negativo A classe que não estamos buscando prever foi prevista incorretamente.


--código python



Portanto, a utilização de machine learning em saúde, pode auxiliar na detecção precoce de doenças cardíacas dando indicios sobre a existência ou não de uma doença, com um acerto razoável. Quanto ao algoritmo, com um aumento do dados e também uma posterior otimização quanto a seu parâmetros, pode-se obter um resultado ainda melhor. O modelo foi submetido a competição citada anteriormente e pontuamos entre os 11% melhores.



